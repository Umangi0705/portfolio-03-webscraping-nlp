{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit API Classification & Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom Ludlow, DSI-NY-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLP to identify posts from **r/audioengineering** and **r/livesound**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 4: Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# preprocessing imports\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state var\n",
    "r = 1220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./csv/181220_X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('./csv/181220_X_test.csv', index_col=0)\n",
    "y_train = pd.read_csv('./csv/181220_y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('./csv/181220_y_test.csv', index_col=0)\n",
    "\n",
    "X_train_post = X_train['post_lm']\n",
    "X_test_post = X_test['post_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_st</th>\n",
       "      <th>post_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>look for book hi i'm look for book or document...</td>\n",
       "      <td>looking for book hi i'm looking for book or do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>where to appli i recent finish a record and pr...</td>\n",
       "      <td>where to apply i recently finished a recording...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>monitor tip gener work with a pro2 hey guy i k...</td>\n",
       "      <td>monitor tip generally work with a pro2 hey guy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>what' the dumbest thing you'v ever heard on a ...</td>\n",
       "      <td>what's the dumbest thing you've ever heard on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>mix classic for the first time next week what ...</td>\n",
       "      <td>mixing classical for the first time next week ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post_st  \\\n",
       "575   look for book hi i'm look for book or document...   \n",
       "584   where to appli i recent finish a record and pr...   \n",
       "1187  monitor tip gener work with a pro2 hey guy i k...   \n",
       "1569  what' the dumbest thing you'v ever heard on a ...   \n",
       "1135  mix classic for the first time next week what ...   \n",
       "\n",
       "                                                post_lm  \n",
       "575   looking for book hi i'm looking for book or do...  \n",
       "584   where to apply i recently finished a recording...  \n",
       "1187  monitor tip generally work with a pro2 hey guy...  \n",
       "1569  what's the dumbest thing you've ever heard on ...  \n",
       "1135  mixing classical for the first time next week ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selections: \n",
    "#### 1. Lemmatized CountVectorizer Multinomial Naive-Bayes\n",
    "  - `cv__ngram_range=(1,2)`\n",
    "  - `cv__stop_words='english'`\n",
    "  \n",
    "#### 2. Lemmatized CountVectorizer Random Forest\n",
    "*(project requirement)*\n",
    "  - `cv__ngram_range=(1,1)`\n",
    "  - `cv__stop_words='english'`\n",
    "  \n",
    "#### 3. Lemmatized CountVectorizer Gradient-Boost Decision Tree\n",
    "  - `cv__ngram_range=(1,2)`\n",
    "  - `cv__stop_words='english'`\n",
    "  \n",
    "#### 4. Lemmatized TF-IDF Scaled Logistic Regression\n",
    "  - `cv__ngram_range=(1,2)`\n",
    "  - `cv__stop_words='english'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Approach\n",
    "\n",
    "For each model, we have set up a `runs` DataFrame to store the parameters and results of each GridSearch.  The GridSearch is set to a `random_state` value, so that cross validation selection will be consistent between runs, and we will be able to make direct comparisons over effectiveness of hyperparameters.\n",
    "\n",
    "We start with a wide range for fields of interest, and narrow around the optimally selected value and gauge the degree of accuracy increase (or decrease).  Through trial and error, we are able to select hyperparameters that will promote the most accurate modeling results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate DataFrame to store results of each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992992</td>\n",
       "      <td>0.829832</td>\n",
       "      <td>{'cv__max_features': None, 'mnb__alpha': 1.5}</td>\n",
       "      <td>196</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987386</td>\n",
       "      <td>0.834034</td>\n",
       "      <td>{'cv__max_features': 35000, 'mnb__alpha': 1.2}</td>\n",
       "      <td>193</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.992992       0.829832   \n",
       "1        0.987386       0.834034   \n",
       "\n",
       "                                               bp   tn  fp  fn   tp  \n",
       "0   {'cv__max_features': None, 'mnb__alpha': 1.5}  196  35  46  199  \n",
       "1  {'cv__max_features': 35000, 'mnb__alpha': 1.2}  193  38  41  204  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1220 # random_state variable for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline, formatted to call named estimators\n",
    "mnb_params = {\"mnb__alpha\":np.arange(1,1.5,.1), \"cv__max_features\":[32500,35000,37500]}\n",
    "\n",
    "# steps defining pipeline sequence and fixed parameters for GridSearch\n",
    "mnb_steps = [('cv',CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "            ('mnb',MultinomialNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish model pipeline by reference to steps list\n",
    "pipe = Pipeline(mnb_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9880868955851436\n",
      "Test Accuracy:  0.8298319327731093\n",
      "BP:  {'cv__max_features': 35000, 'mnb__alpha': 1.1}\n",
      "True Negatives: 192\n",
      "False Positives: 39\n",
      "False Negatives: 42\n",
      "True Positives: 203\n"
     ]
    }
   ],
   "source": [
    "mnb_post_results = {} # empty dict to store results\n",
    "\n",
    "grid = GridSearchCV(pipe, mnb_params, cv=5) # optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "grid.fit(X_train_post, y_train.is_ls) # fit to our training data\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train.is_ls))\n",
    "mnb_post_results['train_accuracy'] = grid.score(X_train_post, y_train.is_ls) # print/store training accuracy\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test.is_ls))\n",
    "mnb_post_results['test_accuracy'] = grid.score(X_test_post, y_test.is_ls) # print/store test accuracy\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "mnb_post_results['bp'] = grid.best_params_ # print/store best parameters\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel() # inspect counted results in matrix\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "mnb_post_results['tn'] = tn\n",
    "print(\"False Positives: %s\" % fp)\n",
    "mnb_post_results['fp'] = fp\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "mnb_post_results['fn'] = fn\n",
    "print(\"True Positives: %s\" % tp)\n",
    "mnb_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result Metrics: Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8298319327731093"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "(mnb_post_results['tn'] + mnb_post_results['tp']) \\\n",
    "    / (mnb_post_results['tn'] + mnb_post_results['fp'] \\\n",
    "       + mnb_post_results['fn'] + mnb_post_results['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285714285714286"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "mnb_post_results['tp'] / (mnb_post_results['tp'] + mnb_post_results['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8311688311688312"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "mnb_post_results['tn'] / (mnb_post_results['tn'] + mnb_post_results['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8388429752066116"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "mnb_post_results['tp'] / (mnb_post_results['tp'] + mnb_post_results['fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to run DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_runs = mnb_runs.append(mnb_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992992</td>\n",
       "      <td>0.829832</td>\n",
       "      <td>{'cv__max_features': None, 'mnb__alpha': 1.5}</td>\n",
       "      <td>196</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987386</td>\n",
       "      <td>0.834034</td>\n",
       "      <td>{'cv__max_features': 35000, 'mnb__alpha': 1.2}</td>\n",
       "      <td>193</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.988087</td>\n",
       "      <td>0.829832</td>\n",
       "      <td>{'cv__max_features': 35000, 'mnb__alpha': 1.1}</td>\n",
       "      <td>192</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.992992       0.829832   \n",
       "1        0.987386       0.834034   \n",
       "2        0.988087       0.829832   \n",
       "\n",
       "                                               bp   tn  fp  fn   tp  \n",
       "0   {'cv__max_features': None, 'mnb__alpha': 1.5}  196  35  46  199  \n",
       "1  {'cv__max_features': 35000, 'mnb__alpha': 1.2}  193  38  41  204  \n",
       "2  {'cv__max_features': 35000, 'mnb__alpha': 1.1}  192  39  42  203  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not yet satisfied with our accuracy and confusion matrix results, we return to the `mnb_params` ranges and modify to narrow or broaden one or more hyperparameters.  Any we are satisfied with can be set to our single desired hyperparameter, which will decrease our GridSearch execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate from here to retain stored run data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844429</td>\n",
       "      <td>0.775210</td>\n",
       "      <td>{'cv__max_features': None, 'rf__criterion': 'g...</td>\n",
       "      <td>137</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.858444</td>\n",
       "      <td>0.775210</td>\n",
       "      <td>{'cv__max_features': None, 'rf__criterion': 'g...</td>\n",
       "      <td>139</td>\n",
       "      <td>92</td>\n",
       "      <td>15</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866854</td>\n",
       "      <td>0.796218</td>\n",
       "      <td>{'cv__max_features': None, 'rf__criterion': 'g...</td>\n",
       "      <td>146</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.844429       0.775210   \n",
       "1        0.858444       0.775210   \n",
       "2        0.866854       0.796218   \n",
       "\n",
       "                                                  bp   tn  fp  fn   tp  \n",
       "0  {'cv__max_features': None, 'rf__criterion': 'g...  137  94  13  232  \n",
       "1  {'cv__max_features': None, 'rf__criterion': 'g...  139  92  15  230  \n",
       "2  {'cv__max_features': None, 'rf__criterion': 'g...  146  85  12  233  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"rf__n_estimators\":np.arange(98,102,1), \"rf__max_depth\": [7,8,9], \n",
    "             \"rf__criterion\":['gini',], \"cv__max_features\":[None,35000,40000,45000]}\n",
    "rf_steps = [('cv',CountVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "             ('rf',RandomForestClassifier(random_state=r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(rf_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.866853538892782\n",
      "Test Accuracy:  0.7962184873949579\n",
      "BP:  {'cv__max_features': None, 'rf__criterion': 'gini', 'rf__max_depth': 9, 'rf__n_estimators': 99}\n",
      "True Negatives: 146\n",
      "False Positives: 85\n",
      "False Negatives: 12\n",
      "True Positives: 233\n"
     ]
    }
   ],
   "source": [
    "rf_post_results = {}\n",
    "\n",
    "grid = GridSearchCV(pipe, rf_params, cv=5)\n",
    "grid.fit(X_train_post, y_train.is_ls)\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train.is_ls))\n",
    "rf_post_results['train_accuracy'] = grid.score(X_train_post, y_train.is_ls)\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test.is_ls))\n",
    "rf_post_results['test_accuracy'] = grid.score(X_test_post, y_test.is_ls)\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "rf_post_results['bp'] = grid.best_params_\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "rf_post_results['tn'] = tn\n",
    "print(\"False Positives: %s\" % fp)\n",
    "rf_post_results['fp'] = fp\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "rf_post_results['fn'] = fn\n",
    "print(\"True Positives: %s\" % tp)\n",
    "rf_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result Metrics: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962184873949579"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "(rf_post_results['tn'] + rf_post_results['tp']) \\\n",
    "    / (rf_post_results['tn'] + rf_post_results['fp'] \\\n",
    "       + rf_post_results['fn'] + rf_post_results['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9510204081632653"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "rf_post_results['tp'] / (rf_post_results['tp'] + rf_post_results['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6320346320346321"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "rf_post_results['tn'] / (rf_post_results['tn'] + rf_post_results['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327044025157232"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "rf_post_results['tp'] / (rf_post_results['tp'] + rf_post_results['fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save run to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_runs = rf_runs.append(rf_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844429</td>\n",
       "      <td>0.775210</td>\n",
       "      <td>{'cv__max_features': None, 'rf__criterion': 'g...</td>\n",
       "      <td>137</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.858444</td>\n",
       "      <td>0.775210</td>\n",
       "      <td>{'cv__max_features': None, 'rf__criterion': 'g...</td>\n",
       "      <td>139</td>\n",
       "      <td>92</td>\n",
       "      <td>15</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866854</td>\n",
       "      <td>0.796218</td>\n",
       "      <td>{'cv__max_features': None, 'rf__criterion': 'g...</td>\n",
       "      <td>146</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.844429       0.775210   \n",
       "1        0.858444       0.775210   \n",
       "2        0.866854       0.796218   \n",
       "\n",
       "                                                  bp   tn  fp  fn   tp  \n",
       "0  {'cv__max_features': None, 'rf__criterion': 'g...  137  94  13  232  \n",
       "1  {'cv__max_features': None, 'rf__criterion': 'g...  139  92  15  230  \n",
       "2  {'cv__max_features': None, 'rf__criterion': 'g...  146  85  12  233  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Boost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate from here to retain stored run data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998598</td>\n",
       "      <td>0.80042</td>\n",
       "      <td>{'cv__max_features': None, 'gb__loss': 'devian...</td>\n",
       "      <td>168</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998598</td>\n",
       "      <td>0.80042</td>\n",
       "      <td>{'cv__max_features': None, 'gb__loss': 'devian...</td>\n",
       "      <td>168</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.998598        0.80042   \n",
       "1        0.998598        0.80042   \n",
       "\n",
       "                                                  bp   tn  fp  fn   tp  \n",
       "0  {'cv__max_features': None, 'gb__loss': 'devian...  168  63  32  213  \n",
       "1  {'cv__max_features': None, 'gb__loss': 'devian...  168  63  32  213  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {\"gb__loss\":['deviance'], \"gb__n_estimators\": np.arange(97,103,1), \n",
    "             \"gb__max_depth\":np.arange(5,9,1), \"cv__max_features\":[None]}\n",
    "gb_steps = [('cv',CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "             ('gb',GradientBoostingClassifier(random_state=r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(gb_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9985984583041345\n",
      "Test Accuracy:  0.8004201680672269\n",
      "BP:  {'cv__max_features': None, 'gb__loss': 'deviance', 'gb__max_depth': 7, 'gb__n_estimators': 100}\n",
      "True Negatives: 168\n",
      "False Positives: 63\n",
      "False Negatives: 32\n",
      "True Positives: 213\n"
     ]
    }
   ],
   "source": [
    "gb_post_results = {}\n",
    "\n",
    "grid = GridSearchCV(pipe, gb_params, cv=3) # set cross validation count to 3 to reduce processing time\n",
    "grid.fit(X_train_post, y_train.is_ls)\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train.is_ls))\n",
    "gb_post_results['train_accuracy'] = grid.score(X_train_post, y_train.is_ls)\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test.is_ls))\n",
    "gb_post_results['test_accuracy'] = grid.score(X_test_post, y_test.is_ls)\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "gb_post_results['bp'] = grid.best_params_\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "gb_post_results['tn'] = tn\n",
    "print(\"False Positives: %s\" % fp)\n",
    "gb_post_results['fp'] = fp\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "gb_post_results['fn'] = fn\n",
    "print(\"True Positives: %s\" % tp)\n",
    "gb_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result Metrics: Gradient-Boost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8004201680672269"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "(gb_post_results['tn'] + gb_post_results['tp']) \\\n",
    "    / (gb_post_results['tn'] + gb_post_results['fp'] \\\n",
    "       + gb_post_results['fn'] + gb_post_results['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693877551020408"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "gb_post_results['tp'] / (gb_post_results['tp'] + gb_post_results['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "gb_post_results['tn'] / (gb_post_results['tn'] + gb_post_results['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7717391304347826"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "gb_post_results['tp'] / (gb_post_results['tp'] + gb_post_results['fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save run to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_runs = gb_runs.append(gb_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998598</td>\n",
       "      <td>0.80042</td>\n",
       "      <td>{'cv__max_features': None, 'gb__loss': 'devian...</td>\n",
       "      <td>168</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998598</td>\n",
       "      <td>0.80042</td>\n",
       "      <td>{'cv__max_features': None, 'gb__loss': 'devian...</td>\n",
       "      <td>168</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998598</td>\n",
       "      <td>0.80042</td>\n",
       "      <td>{'cv__max_features': None, 'gb__loss': 'devian...</td>\n",
       "      <td>168</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998598</td>\n",
       "      <td>0.80042</td>\n",
       "      <td>{'cv__max_features': None, 'gb__loss': 'devian...</td>\n",
       "      <td>168</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.998598        0.80042   \n",
       "1        0.998598        0.80042   \n",
       "2        0.998598        0.80042   \n",
       "3        0.998598        0.80042   \n",
       "\n",
       "                                                  bp   tn  fp  fn   tp  \n",
       "0  {'cv__max_features': None, 'gb__loss': 'devian...  168  63  32  213  \n",
       "1  {'cv__max_features': None, 'gb__loss': 'devian...  168  63  32  213  \n",
       "2  {'cv__max_features': None, 'gb__loss': 'devian...  168  63  32  213  \n",
       "3  {'cv__max_features': None, 'gb__loss': 'devian...  168  63  32  213  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate from here to retain stored run data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\"lr__penalty\":['l1'], \"lr__C\": [1.2],\n",
    "             \"lr__tol\":[.00035], \"tf__max_features\":[25000,27500,30000,32500,35000]}\n",
    "lr_steps = [('tf',TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "            ('sc',StandardScaler(with_mean=False)),\n",
    "            ('lr',LogisticRegression(random_state=r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(lr_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.999299229152\n",
      "Test Accuracy:  0.806722689076\n",
      "BP:  {'lr__C': 1.2, 'lr__penalty': 'l1', 'lr__tol': 0.00035, 'tf__max_features': 32500}\n",
      "True Negatives: 193\n",
      "False Positives: 38\n",
      "False Negatives: 54\n",
      "True Positives: 191\n"
     ]
    }
   ],
   "source": [
    "lr_post_results = {}\n",
    "\n",
    "grid = GridSearchCV(pipe, lr_params, cv=3)\n",
    "grid.fit(X_train_post, y_train.is_ls)\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train.is_ls))\n",
    "lr_post_results['train_accuracy'] = grid.score(X_train_post, y_train.is_ls)\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test.is_ls))\n",
    "lr_post_results['test_accuracy'] = grid.score(X_test_post, y_test.is_ls)\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "lr_post_results['bp'] = grid.best_params_\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "lr_post_results['tn'] = tn\n",
    "print(\"False Positives: %s\" % fp)\n",
    "lr_post_results['fp'] = fp\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "lr_post_results['fn'] = fn\n",
    "print(\"True Positives: %s\" % tp)\n",
    "lr_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result Metrics: TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80672268907563027"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "(lr_post_results['tn'] + lr_post_results['tp']) \\\n",
    "    / (lr_post_results['tn'] + lr_post_results['fp'] \\\n",
    "       + lr_post_results['fn'] + lr_post_results['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795918367346939"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "lr_post_results['tp'] / (lr_post_results['tp'] + lr_post_results['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83549783549783552"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "lr_post_results['tn'] / (lr_post_results['tn'] + lr_post_results['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83406113537117899"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "lr_post_results['tp'] / (lr_post_results['tp'] + lr_post_results['fp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save run to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_runs = lr_runs.append(lr_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>{'lr__C': 1, 'lr__penalty': 'l1', 'lr__tol': 0...</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.804622</td>\n",
       "      <td>{'lr__C': 1, 'lr__penalty': 'l1', 'lr__tol': 0...</td>\n",
       "      <td>190</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>{'lr__C': 1.1, 'lr__penalty': 'l1', 'lr__tol':...</td>\n",
       "      <td>186</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>{'lr__C': 1.1, 'lr__penalty': 'l1', 'lr__tol':...</td>\n",
       "      <td>186</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.804622</td>\n",
       "      <td>{'lr__C': 1.2000000000000002, 'lr__penalty': '...</td>\n",
       "      <td>192</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.999299       0.821429   \n",
       "1        0.999299       0.804622   \n",
       "2        0.999299       0.789916   \n",
       "3        0.999299       0.789916   \n",
       "4        0.999299       0.804622   \n",
       "\n",
       "                                                  bp   tn  fp  fn   tp  \n",
       "0  {'lr__C': 1, 'lr__penalty': 'l1', 'lr__tol': 0...  195  36  49  196  \n",
       "1  {'lr__C': 1, 'lr__penalty': 'l1', 'lr__tol': 0...  190  41  52  193  \n",
       "2  {'lr__C': 1.1, 'lr__penalty': 'l1', 'lr__tol':...  186  45  55  190  \n",
       "3  {'lr__C': 1.1, 'lr__penalty': 'l1', 'lr__tol':...  186  45  55  190  \n",
       "4  {'lr__C': 1.2000000000000002, 'lr__penalty': '...  192  39  54  191  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 1, 'lr__penalty': 'l1', 'lr__tol': 0.001, 'tf__max_features': 30000}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_runs.loc[0]['bp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model Features\n",
    " \n",
    "**Model 1:** Multinomial Naive-Bayes\n",
    " - *Lemmatizer*\n",
    " - *CountVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,2)`\n",
    " - *GridSearch*\n",
    "  - `cv__max_features=35000`\n",
    "  - `mnb__alpha=1.2`\n",
    " \n",
    "**Model 2:** Random Forest\n",
    " - *Lemmatizer*\n",
    " - *CountVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,1)`\n",
    " - *GridSearch*\n",
    "  - `cv__max_features=None`\n",
    "  - `rf__criterion='gini'`\n",
    "  - `rf__n_estimators=99`\n",
    "  - `rf__max_depth=9`\n",
    "  - `rf__max_features='sqrt'`\n",
    "  \n",
    "**Model 3:** Gradient-Boost Decision Tree\n",
    " - *Lemmatizer*\n",
    " - *CountVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,2)`\n",
    " - *GridSearch*\n",
    "  - `cv__max_features=None`\n",
    "  - `gb__loss='deviance'`\n",
    "  - `gb__max_depth=7`\n",
    "  - `gb__n_estimators=100`\n",
    "  \n",
    "**Model 4:** TF-IDF Logistic Regression\n",
    " - *Lemmatizer*\n",
    " - *TfidfVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,2)`\n",
    " - *GridSearch*\n",
    "  - `tf__max_features=30000`\n",
    "  - `lr__penalty='l1'`\n",
    "  - `lr__C=1`\n",
    "  - `lr__tol=.001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model hyperparameters optimized through GridSearch, we build each desired model pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 Optimized: Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_steps = [('m1_cv',CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=35000)),\n",
    "           ('m1_mnb',MultinomialNB(alpha=1.2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1 = Pipeline(m1_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('m1_cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=35000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('m1_mnb', MultinomialNB(alpha=1.2, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9873861247372109"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340336134453782"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 193\n",
      "False Positives: 38\n",
      "False Negatives: 41\n",
      "True Positives: 204\n",
      "\n",
      "Accuracy:  0.8340336134453782\n",
      "Sensitivity:  0.8326530612244898\n",
      "Specificity:  0.8354978354978355\n",
      "Precision:  0.8429752066115702\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test.is_ls, pipe_1.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 Optimized: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_steps = [('m2_cv',CountVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "           ('m2_rf',RandomForestClassifier(criterion='gini', n_estimators=99, max_depth=9))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_2 = Pipeline(m2_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('m2_cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "       ...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703573931324456"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7689075630252101"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 140\n",
      "False Positives: 91\n",
      "False Negatives: 19\n",
      "True Positives: 226\n",
      "\n",
      "Accuracy:  0.7689075630252101\n",
      "Sensitivity:  0.9224489795918367\n",
      "Specificity:  0.6060606060606061\n",
      "Precision:  0.7129337539432177\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test.is_ls, pipe_2.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Optimized: Gradient-Boost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_steps = [('m3_cv',CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=None)),\n",
    "           ('m3_gb',GradientBoostingClassifier(loss='deviance', n_estimators=100, max_depth=7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_3 = Pipeline(m3_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('m3_cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "       ...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985984583041345"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878151260504201"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 163\n",
      "False Positives: 68\n",
      "False Negatives: 33\n",
      "True Positives: 212\n",
      "\n",
      "Accuracy:  0.7878151260504201\n",
      "Sensitivity:  0.8653061224489796\n",
      "Specificity:  0.7056277056277056\n",
      "Precision:  0.7571428571428571\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test.is_ls, pipe_3.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 Optimized: TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_steps = [('tf',TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=30000)),\n",
    "            ('sc',StandardScaler(with_mean=False)),\n",
    "            ('lr',LogisticRegression(penalty='l1', C=1, tol=.001))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_4 = Pipeline(m4_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ... penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99929922915206726"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80042016806722693"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 190\n",
      "False Positives: 41\n",
      "False Negatives: 54\n",
      "True Positives: 191\n",
      "\n",
      "Accuracy:  0.800420168067\n",
      "Sensitivity:  0.779591836735\n",
      "Specificity:  0.822510822511\n",
      "Precision:  0.823275862069\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test.is_ls, pipe_4.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to Notebook 5: Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

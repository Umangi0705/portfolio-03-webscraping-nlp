{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit API Classification & Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom Ludlow, DSI-NY-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLP to identify posts from **r/audioengineering** and **r/livesound**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the process documentation for evaluating 4 optimized NLP classification models.  To test effectiveness against unseen data, the first step was to obtain new Reddit posts from **r/audioengineering** and **r/livesound**, and apply all required pre-processing to create matrices for our models.  Each model is then evaluated using this new data, and a confusion matrix is generated to show the distribution of True Positive, False Positive, False Negative, True Negative predictions.\n",
    "\n",
    "These model results are lastly compared to a Voting Classifier model which combines all of the models and selects a probabilistic result.  Each model's term coefficients are then checked to determine the most and least important values for each model.\n",
    "\n",
    "### Contents:\n",
    "- [**Pull New Reddit Posts**](#Pull-New-Reddit-Posts)\n",
    "- [**EDA**](#EDA)\n",
    "- [**Pre-processing**](#Pre-processing)\n",
    "- [**Optimized Model Evaluation**](#Optimized-Model-Evaluation)\n",
    "    - [Optimized Model Features](#Optimized-Model-Features)\n",
    "    - [Multinomial Naive Bayes](#Model-1-Evaluation:-Multinomial-Naive-Bayes)\n",
    "    - [Random Forest](#Model-2-Evaluation:-Random-Forest)\n",
    "    - [GradientBoost Decision Tree](#Model-3-Evaluation:-GradientBoost-Decision-Tree)\n",
    "    - [TF-IDF Logistic Regression](#Model-4-Evaluation:-TF-IDF-Logistic-Regression)\n",
    "    - [Voting Classifier](#Voting-Classifier-Evaluation)\n",
    "- [**Feature Analysis**](#Feature-Analysis)\n",
    "    - [Multinomial Naive Bayes](#Model-1:-Multinomial-Naive-Bayes-Coefficients)\n",
    "    - [Random Forest](#Model-2:-Random-Forest-Feature-Priority)\n",
    "    - [GradientBoost Decision Tree](#Model-3:-GradientBoost-Decision-Tree-Feature-Priority)\n",
    "    - [TF-IDF Logistic Regression](#Model-4:-Logistic-Regression-Coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# preprocessing imports\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, \\\n",
    "    GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state var\n",
    "r = 1220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull New Reddit Posts\n",
    "#### Loop to pull new Reddit API posts made after 12/14/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create header parameter for API\n",
    "headers_dict = {'User-agent':'twludlow'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200\n",
      "sub01_pages length:  1\n",
      "sub01_after:  t3_a6v1sq\n",
      "0 200\n",
      "sub02_pages length:  1\n",
      "sub02_after:  t3_a67kph\n",
      "https://reddit.com/r/audioengineering.json?limit=50&after=t3_a6v1sq\n",
      "https://reddit.com/r/livesound.json?limit=50&after=t3_a67kph\n",
      "1 200\n",
      "sub01_pages length:  2\n",
      "sub01_after:  t3_a64puo\n",
      "1 200\n",
      "sub02_pages length:  2\n",
      "sub02_after:  t3_a4o87j\n",
      "https://reddit.com/r/audioengineering.json?limit=50&after=t3_a64puo\n",
      "https://reddit.com/r/livesound.json?limit=50&after=t3_a4o87j\n",
      "2 200\n",
      "sub01_pages length:  3\n",
      "sub01_after:  t3_a4fh6e\n",
      "2 200\n",
      "sub02_pages length:  3\n",
      "sub02_after:  t3_a32nmp\n"
     ]
    }
   ],
   "source": [
    "# instantiate API variables\n",
    "url = 'https://reddit.com/'\n",
    "sub01_url = url + 'r/audioengineering' # set sub01 to 'Audio Engineering'\n",
    "sub02_url = url + 'r/livesound'        # set sub02 to 'Live Sound'\n",
    "\n",
    "limit_num = 50      # API 'limit' parameter\n",
    "\n",
    "sub01_after = None  # instantiate empty counters for API 'after' parameter\n",
    "sub02_after = None\n",
    "\n",
    "sub01_pages = []    # instantiate empty lists to save API results\n",
    "sub02_pages = []\n",
    "\n",
    "for i in range(3): # pull from API 3 times\n",
    "    \n",
    "    # add 'after' parameters if an id has been saved - starts as None\n",
    "    if sub01_after and sub02_after:\n",
    "        # create full API url for sub01\n",
    "        sub01_after_url = sub01_url + '.json?limit=' \\\n",
    "                            + str(limit_num) + '&after=' \\\n",
    "                            + sub01_after\n",
    "        print(sub01_after_url)\n",
    "        \n",
    "        # create full API url for sub02\n",
    "        sub02_after_url = sub02_url + '.json?limit=' \\\n",
    "                            + str(limit_num) + '&after=' \\\n",
    "                            + sub02_after\n",
    "        print(sub02_after_url)\n",
    "    \n",
    "    # if one after is logged and the other is not\n",
    "    elif bool(sub01_after) != bool(sub02_after):\n",
    "        print('After reference out of sync.')\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        # create first run url\n",
    "        sub01_after_url = sub01_url + '.json?limit=' + str(limit_num)\n",
    "        sub02_after_url = sub02_url + '.json?limit=' + str(limit_num)\n",
    "    \n",
    "    # pull json from sub01\n",
    "    sub01_res = requests.get(sub01_after_url, headers=headers_dict)\n",
    "    print(i, sub01_res.status_code)\n",
    "    \n",
    "    # if sub01 connection is established\n",
    "    if sub01_res.status_code == 200:\n",
    "        # add page to list\n",
    "        sub01_pages.append(sub01_res.json()['data'])\n",
    "        print('sub01_pages length: ', len(sub01_pages))\n",
    "        \n",
    "        # set 'after' parameter for next run\n",
    "        sub01_after = sub01_res.json()['data']['after']\n",
    "        print('sub01_after: ', sub01_after)\n",
    "        \n",
    "    else:        \n",
    "        print('Connection failed.\\n')\n",
    "    \n",
    "    # sleep one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # pull json from sub02\n",
    "    sub02_res = requests.get(sub02_after_url, headers=headers_dict)\n",
    "    print(i, sub02_res.status_code)\n",
    "    \n",
    "    # if sub02 connection is established\n",
    "    if sub02_res.status_code == 200:\n",
    "        # add page to list\n",
    "        sub02_pages.append(sub02_res.json()['data'])\n",
    "        print('sub02_pages length: ', len(sub02_pages))\n",
    "        \n",
    "        # set 'after' parameter for next run\n",
    "        sub02_after = sub02_res.json()['data']['after']\n",
    "        print('sub02_after: ', sub02_after)\n",
    "    else:\n",
    "        print('Connection failed.\\n')\n",
    "        \n",
    "    # sleep one second    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrames from posting lists\n",
    "sub01_df = pd.DataFrame(sub01_pages)\n",
    "sub02_df = pd.DataFrame(sub02_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save API data to files\n",
    "sub01_df.to_csv('./NEW_audio_engineering_posts.csv', index=False)\n",
    "sub02_df.to_csv('./NEW_live_sound_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves: NEW_audioengineering_posts.csv, NEW_live_sound_posts.csv\n",
    "\n",
    "Iterations: 3 x 50 posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA \n",
    "**(repeat process of original training data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub01_df = pd.read_csv('./reddit_data/NEW_audio_engineering_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub02_df = pd.read_csv('./reddit_data/NEW_live_sound_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub01_df['children'] = sub01_df.children.map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub02_df['children'] = sub02_df.children.map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting changes after loading from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>before</th>\n",
       "      <th>children</th>\n",
       "      <th>dist</th>\n",
       "      <th>modhash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_a6v1sq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'kind': 't3', 'data': {'approved_at_utc': No...</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_a64puo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'kind': 't3', 'data': {'approved_at_utc': No...</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_a4fh6e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'kind': 't3', 'data': {'approved_at_utc': No...</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       after  before                                           children  dist  \\\n",
       "0  t3_a6v1sq     NaN  [{'kind': 't3', 'data': {'approved_at_utc': No...    52   \n",
       "1  t3_a64puo     NaN  [{'kind': 't3', 'data': {'approved_at_utc': No...    50   \n",
       "2  t3_a4fh6e     NaN  [{'kind': 't3', 'data': {'approved_at_utc': No...    50   \n",
       "\n",
       "   modhash  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub01_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub01_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>before</th>\n",
       "      <th>children</th>\n",
       "      <th>dist</th>\n",
       "      <th>modhash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_a67kph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'kind': 't3', 'data': {'approved_at_utc': No...</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_a4o87j</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'kind': 't3', 'data': {'approved_at_utc': No...</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_a32nmp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'kind': 't3', 'data': {'approved_at_utc': No...</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       after  before                                           children  dist  \\\n",
       "0  t3_a67kph     NaN  [{'kind': 't3', 'data': {'approved_at_utc': No...    52   \n",
       "1  t3_a4o87j     NaN  [{'kind': 't3', 'data': {'approved_at_utc': No...    50   \n",
       "2  t3_a32nmp     NaN  [{'kind': 't3', 'data': {'approved_at_utc': No...    50   \n",
       "\n",
       "   modhash  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub02_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub02_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save post dictionaries in arrays\n",
    "\n",
    "ae_posts_bulk = sub01_df['children']\n",
    "ls_posts_bulk = sub02_df['children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'kind': 't3', 'data': {'approved_at_utc': No...\n",
       "1    [{'kind': 't3', 'data': {'approved_at_utc': No...\n",
       "2    [{'kind': 't3', 'data': {'approved_at_utc': No...\n",
       "Name: children, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_posts_bulk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'kind': 't3', 'data': {'approved_at_utc': No...\n",
       "1    [{'kind': 't3', 'data': {'approved_at_utc': No...\n",
       "2    [{'kind': 't3', 'data': {'approved_at_utc': No...\n",
       "Name: children, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_posts_bulk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_posts_bulk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for post in ae_posts_bulk: \n",
    "    print(len(post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unravel posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Title: 'title'\n",
    " - Posts: 'selftext'\n",
    " - Author: 'author_fullname'\n",
    " - Upvotes: 'ups'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tech Support and Troubleshooting - December 17, 2018'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_posts_bulk[0][0]['data']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Welcome the /r/audioengineering Tech Support and Troubleshooting Thread.  We kindly ask that all tech support questions and basic troubleshooting questions (how do I hook up 'a' to 'b'?, headphones vs mons, etc) go here.  If you see posts that belong here, please report them to help us get to them in a timely manner.  Thank you!\\n\\n   Daily Threads:\\n\\n\\n* [Monday - Gear Recommendations Sticky Thread](http://www.reddit.com/r/audioengineering/search?q=title%3Arecommendation+author%3Aautomoderator&amp;restrict_sr=on&amp;sort=new&amp;t=all)\\n* [Monday - Tech Support and Troubleshooting Sticky Thread](http://www.reddit.com/r/audioengineering/search?q=title%3ASupport+author%3Aautomoderator&amp;restrict_sr=on&amp;sort=new&amp;t=all)\\n* [Tuesday - Tips &amp; Tricks](http://www.reddit.com/r/audioengineering/search?q=title%3A%22tuesdays%22+AND+%28author%3Aautomoderator+OR+author%3Ajaymz168%29&amp;restrict_sr=on&amp;sort=new&amp;t=all)\\n* [Friday - How did they do that?](http://www.reddit.com/r/audioengineering/search?q=title%3AFriday+author%3Aautomoderator&amp;restrict_sr=on&amp;sort=new&amp;t=all)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_posts_bulk[0][0]['data']['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Post the pictures you took at your gigs this week!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_posts_bulk[0][0]['data']['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t2_6l4z3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_posts_bulk[0][0]['data']['author_fullname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t2_6l4z3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_posts_bulk[0][0]['data']['author_fullname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_posts_bulk[0][0]['data']['ups']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post titles - 'title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_titles = [ae_posts_bulk[i][j]['data']['title'] for i in range(len(ae_posts_bulk)) \n",
    "            for j in range(len(ae_posts_bulk[i]))]\n",
    "ls_titles = [ls_posts_bulk[i][j]['data']['title'] for i in range(len(ls_posts_bulk)) \n",
    "            for j in range(len(ls_posts_bulk[i]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posts - 'selftext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of post using nested comprehensions\n",
    "ae_posts = [ae_posts_bulk[i][j]['data']['selftext'] for i in range(len(ae_posts_bulk)) \n",
    "            for j in range(len(ae_posts_bulk[i]))]\n",
    "ls_posts = [ls_posts_bulk[i][j]['data']['selftext'] for i in range(len(ls_posts_bulk)) \n",
    "            for j in range(len(ls_posts_bulk[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ae_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upvotes - 'ups'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_ups = [ae_posts_bulk[i][j]['data']['ups'] for i in range(len(ae_posts_bulk)) \n",
    "            for j in range(len(ae_posts_bulk[i]))]\n",
    "ls_ups = [ls_posts_bulk[i][j]['data']['ups'] for i in range(len(ls_posts_bulk)) \n",
    "            for j in range(len(ls_posts_bulk[i]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors - 'author_fullname'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing manually to handle missing author data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_authors = []\n",
    "ls_authors = []\n",
    "\n",
    "for i in range(len(ae_posts_bulk)):\n",
    "    for j in range(len(ae_posts_bulk[i])):\n",
    "        try:\n",
    "            ae_authors.append(ae_posts_bulk[i][j]['data']['author_fullname'])\n",
    "        except:\n",
    "            ae_authors.append('no author')\n",
    "            \n",
    "for i in range(len(ls_posts_bulk)):\n",
    "    for j in range(len(ls_posts_bulk[i])):                \n",
    "        try:\n",
    "            ls_authors.append(ls_posts_bulk[i][j]['data']['author_fullname'])\n",
    "        except:\n",
    "            ls_authors.append('no author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ae_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile lists into DataFrame\n",
    "ae_df = pd.DataFrame([ae_titles, ae_posts, ae_authors, ae_ups], index=['title','post','author','upvotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose from rows to columns\n",
    "ae_df = ae_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile lists into DataFrame\n",
    "ls_df = pd.DataFrame([ls_titles, ls_posts, ls_authors, ls_ups], index=['title','post','author','upvotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose from rows to columns\n",
    "ls_df = ls_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save separate DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_df.to_csv('./csv/NEW_ae_df.csv', index=False)\n",
    "ls_df.to_csv('./csv/NEW_ls_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize our classifier: 'is_ls' (is live sound)\n",
    "ae_df['is_ls'] = 0\n",
    "ls_df['is_ls'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ae_df, ls_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>author</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>is_ls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tech Support and Troubleshooting - December 17...</td>\n",
       "      <td>Welcome the /r/audioengineering Tech Support a...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gear Recommendation (What Should I Buy?) Threa...</td>\n",
       "      <td>Welcome to our weekly Gear Recommendation Thre...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is a ThunderBolt audio interface worth it for ...</td>\n",
       "      <td>Right now I record through a crappy AudioBox U...</td>\n",
       "      <td>t2_24wuqxkk</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What’s the difference b/w dithering and trunca...</td>\n",
       "      <td>It’s my basic understanding that dithering is ...</td>\n",
       "      <td>t2_y139dwj</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting wide auto-panning to sound right/auto-...</td>\n",
       "      <td>I’ve noticed that a lot of songs I really enjo...</td>\n",
       "      <td>t2_4anq6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Tech Support and Troubleshooting - December 17...   \n",
       "1  Gear Recommendation (What Should I Buy?) Threa...   \n",
       "2  Is a ThunderBolt audio interface worth it for ...   \n",
       "3  What’s the difference b/w dithering and trunca...   \n",
       "4  Getting wide auto-panning to sound right/auto-...   \n",
       "\n",
       "                                                post       author upvotes  \\\n",
       "0  Welcome the /r/audioengineering Tech Support a...     t2_6l4z3       8   \n",
       "1  Welcome to our weekly Gear Recommendation Thre...     t2_6l4z3       6   \n",
       "2  Right now I record through a crappy AudioBox U...  t2_24wuqxkk      31   \n",
       "3  It’s my basic understanding that dithering is ...   t2_y139dwj       9   \n",
       "4  I’ve noticed that a lot of songs I really enjo...     t2_4anq6       4   \n",
       "\n",
       "   is_ls  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    152\n",
       "0    152\n",
       "Name: is_ls, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_ls.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.post.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comb'] = df['title'] + ' ' + df['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for empty posts and store index to list\n",
    "to_drop = []\n",
    "\n",
    "for i, post in enumerate(df['comb']):\n",
    "    if len(post)==0:\n",
    "        to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with empty posts using index list\n",
    "df.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    152\n",
       "0    152\n",
       "Name: is_ls, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_ls.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./csv/NEW_post_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last saved 12/19/18 as NEW_post_df.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./csv/NEW_post_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tech Support and Troubleshooting - December 17...\n",
       "1    Gear Recommendation (What Should I Buy?) Threa...\n",
       "2    Is a ThunderBolt audio interface worth it for ...\n",
       "3    What’s the difference b/w dithering and trunca...\n",
       "4    Getting wide auto-panning to sound right/auto-...\n",
       "Name: comb, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>author</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>is_ls</th>\n",
       "      <th>comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tech Support and Troubleshooting - December 17...</td>\n",
       "      <td>Welcome the /r/audioengineering Tech Support a...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Tech Support and Troubleshooting - December 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gear Recommendation (What Should I Buy?) Threa...</td>\n",
       "      <td>Welcome to our weekly Gear Recommendation Thre...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Gear Recommendation (What Should I Buy?) Threa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is a ThunderBolt audio interface worth it for ...</td>\n",
       "      <td>Right now I record through a crappy AudioBox U...</td>\n",
       "      <td>t2_24wuqxkk</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>Is a ThunderBolt audio interface worth it for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What’s the difference b/w dithering and trunca...</td>\n",
       "      <td>It’s my basic understanding that dithering is ...</td>\n",
       "      <td>t2_y139dwj</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>What’s the difference b/w dithering and trunca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting wide auto-panning to sound right/auto-...</td>\n",
       "      <td>I’ve noticed that a lot of songs I really enjo...</td>\n",
       "      <td>t2_4anq6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Getting wide auto-panning to sound right/auto-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Tech Support and Troubleshooting - December 17...   \n",
       "1  Gear Recommendation (What Should I Buy?) Threa...   \n",
       "2  Is a ThunderBolt audio interface worth it for ...   \n",
       "3  What’s the difference b/w dithering and trunca...   \n",
       "4  Getting wide auto-panning to sound right/auto-...   \n",
       "\n",
       "                                                post       author  upvotes  \\\n",
       "0  Welcome the /r/audioengineering Tech Support a...     t2_6l4z3        8   \n",
       "1  Welcome to our weekly Gear Recommendation Thre...     t2_6l4z3        6   \n",
       "2  Right now I record through a crappy AudioBox U...  t2_24wuqxkk       31   \n",
       "3  It’s my basic understanding that dithering is ...   t2_y139dwj        9   \n",
       "4  I’ve noticed that a lot of songs I really enjo...     t2_4anq6        4   \n",
       "\n",
       "   is_ls                                               comb  \n",
       "0      0  Tech Support and Troubleshooting - December 17...  \n",
       "1      0  Gear Recommendation (What Should I Buy?) Threa...  \n",
       "2      0  Is a ThunderBolt audio interface worth it for ...  \n",
       "3      0  What’s the difference b/w dithering and trunca...  \n",
       "4      0  Getting wide auto-panning to sound right/auto-...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing titles and posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = RegexpTokenizer(r\"[\\w/\\']+\") # regex to include words, slash characters for urls, apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121    [Question] EQing Reverbs before or after it? W...\n",
       "297    X32 Complete Backup I can't believe it's been ...\n",
       "160    Sad Shure SM81 - Any ideas? Hey /r/livesound, ...\n",
       "93     Rode NTA-1 Capsule Swap? Edit: May also help i...\n",
       "109    When Using EQ on dialogue does subtle work or ...\n",
       "Name: comb, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comb.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, text in enumerate(df.comb):\n",
    "    text_loop = text.replace('&amp;','&')\n",
    "    text_loop = text_loop.replace('#x200B;',' ') # manually remove symbols &, nzsp, nbsp, \\n\n",
    "    text_loop = text_loop.replace('nbsp;',' ')\n",
    "    df.comb.iloc[i] = text_loop.replace('\\n',' ').strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize each post and save to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comb_tokens = []  # empty token list\n",
    "\n",
    "for i in range(len(df.comb)):\n",
    "    loop_tokens = rt.tokenize(df.comb.iloc[i].lower()) # use iloc to skip removed rows\n",
    "    for j, token in enumerate(loop_tokens):\n",
    "        if re.match(r\"\\d+[\\w]*\", token):\n",
    "            loop_tokens[j] = ''\n",
    "        if re.match(r\"//[\\w]*\", token):\n",
    "            loop_tokens[j] = ''\n",
    "        if ('audioengineering' in token)|('livesound' in token)|('http' in token):\n",
    "            loop_tokens[j] = ''\n",
    "    comb_tokens.append(loop_tokens)                    # add tokenized string to post_tokens list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comb_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comb_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tech', 'support', 'and', 'troubleshooting', 'december']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_tokens[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_t_lm = []\n",
    "\n",
    "for post in comb_tokens:\n",
    "    post_st = [] # empty post stems\n",
    "    for word in post:\n",
    "        #print(word)\n",
    "        word_st = lm.lemmatize(word) # get lemmatized word\n",
    "        post_st.append(word_st) # add to post list\n",
    "    posts_t_lm.append(post_st)  # add post list to lemma matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tech', 'support', 'and', 'troubleshooting', 'december']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_t_lm[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine lemmatized to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_t_lm_list = []\n",
    "\n",
    "for post in posts_t_lm:\n",
    "    posts_t_lm_list.append(' '.join(post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"tech support and troubleshooting december   welcome the  tech support and troubleshooting thread we kindly ask that all tech support question and basic troubleshooting question how do i hook up 'a' to 'b' headphone v mon etc go here if you see post that belong here please report them to help u get to them in a timely manner thank you daily thread monday gear recommendation sticky thread   reddit  q title  author  restrict_sr on sort new t all monday tech support and troubleshooting sticky thread   reddit  q title  author  restrict_sr on sort new t all tuesday tip trick   reddit  q title    and   or author   restrict_sr on sort new t all friday how did they do that   reddit  q title  author  restrict_sr on sort new t all\",\n",
       " 'gear recommendation what should i buy thread december   welcome to our weekly gear recommendation thread where you can ask  for recommendation on smart purchase low cost gear and purchasing recommendation request have become common in the ae subreddit there is also great repetition of model asked about and advised for use this weekly post is intended to assist in centralizing and answering request and recommendation if you see post that belong here please report them to help u get to them in a timely manner thank you daily thread monday gear recommendation sticky thread   reddit  q title  author  restrict_sr on sort new t all monday tech support and troubleshooting sticky thread   reddit  q title  author  restrict_sr on sort new t all tuesday tip trick   reddit  q title    and   or author   restrict_sr on sort new t all friday how did they do that   reddit  q title  author  restrict_sr on sort new t all']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_t_lm_list[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add index to posts and titles and create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.DataFrame(data=[posts_t_lm_list], index=['post_lm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = df_pre.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech support and troubleshooting december   we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gear recommendation what should i buy thread d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is a thunderbolt audio interface worth it for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what s the difference b/w dithering and trunca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>getting wide auto panning to sound right/auto ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_lm\n",
       "0  tech support and troubleshooting december   we...\n",
       "1  gear recommendation what should i buy thread d...\n",
       "2  is a thunderbolt audio interface worth it for ...\n",
       "3  what s the difference b/w dithering and trunca...\n",
       "4  getting wide auto panning to sound right/auto ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre['is_ls'] = df['is_ls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_lm</th>\n",
       "      <th>is_ls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech support and troubleshooting december   we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gear recommendation what should i buy thread d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is a thunderbolt audio interface worth it for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what s the difference b/w dithering and trunca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>getting wide auto panning to sound right/auto ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_lm  is_ls\n",
       "0  tech support and troubleshooting december   we...      0\n",
       "1  gear recommendation what should i buy thread d...      0\n",
       "2  is a thunderbolt audio interface worth it for ...      0\n",
       "3  what s the difference b/w dithering and trunca...      0\n",
       "4  getting wide auto panning to sound right/auto ...      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre.to_csv('./csv/NEW_df_pre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = df_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for and remove duplicate posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df_pre = pd.read_csv('./csv/181219_df_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tech support and troubleshooting december   we...\n",
       "1    gear recommendation what should i buy thread d...\n",
       "2    will i ever understand compression ahh yes my ...\n",
       "3    i'm interviewing to be an intern at a big stud...\n",
       "4    if i faced two speaker towards each other one ...\n",
       "Name: post_lm, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df_pre[old_df_pre.is_ls==0].post_lm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 will i ever understand compression ahh yes my monthly compression post i 'get' the idea of compression but i am struggling so much with how to hear what is reasonable/appropriate/too much when adding compression here's my understanding and please correct me on any or all of this threshold the point where the plug in actually kick in ratio how much of the sound over the threshold is compressed attack length of time before compression kick in release how long compression is held for makeup gain getting the 'lost' volume back from the compression i'm trying to start with understanding the logic house compressor i've picked one to learn studio fet my problem is i can see the needle move and know something is happening but i just can't tell if i've found a sweet spot am i monitoring the whole track while getting the compressor right or picking a particular good point where there might be loud word or soft word and looping it till i get it right i've watched ton of video explanation animation you name it but i just can't get to grip with it i think i need some exercise that will let me practice compression i have a lot of recorded vocal and acoustic guitar so plenty to work with i just need to know what i'm listening for and how to know when i've done it 'right' which i know is subjective also another question i have is do you treat your compression like a mathematical equation i find myself trying to do math with the radio and db's blah blah blah thank you in advance\n"
     ]
    }
   ],
   "source": [
    "for i, newpost in enumerate(new_test[new_test.is_ls==0].post_lm):\n",
    "    if \"will i ever understand compression\" in newpost:\n",
    "        print(i, newpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924    weekly office pic thread week of       post th...\n",
       "925    no stupid question thread week of       the on...\n",
       "926                                      hope this count\n",
       "927            i think we might have to re align the sub\n",
       "928      got to the venue and they have a mystery switch\n",
       "Name: post_lm, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df_pre[old_df_pre.is_ls==1].post_lm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 hope this count\n"
     ]
    }
   ],
   "source": [
    "for i, newpost in enumerate(new_test[new_test.is_ls==1].post_lm):\n",
    "    if \"hope this count\" in newpost:\n",
    "        print(i, newpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152    weekly office pic thread week of       post th...\n",
       "153    no stupid question thread week of       the on...\n",
       "154    the best production timelapse i've seen so wel...\n",
       "155    wireless router/mobile app for a h qu/sq serie...\n",
       "156                               the realest of reverbs\n",
       "Name: post_lm, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test[new_test.is_ls==1].post_lm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hope this count'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.post_lm[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_test.drop(range(79,152), inplace=True)\n",
    "new_test.drop(range(200,304), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79\n",
       "1    48\n",
       "Name: is_ls, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.is_ls.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test.to_csv('./csv/181220_new_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model Features\n",
    " \n",
    "**Model 1:** Multinomial Naive-Bayes\n",
    " - *Lemmatizer*\n",
    " - *CountVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,2)`\n",
    " - *GridSearch*\n",
    "  - `cv__max_features=35000`\n",
    "  - `mnb__alpha=1.2`\n",
    " \n",
    "**Model 2:** Random Forest\n",
    " - *Lemmatizer*\n",
    " - *CountVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,1)`\n",
    " - *GridSearch*\n",
    "  - `cv__max_features=None`\n",
    "  - `rf__criterion='gini'`\n",
    "  - `rf__n_estimators=99`\n",
    "  - `rf__max_depth=9`\n",
    "  - `rf__max_features='sqrt'`\n",
    "  \n",
    "**Model 3:** Gradient-Boost Decision Tree\n",
    " - *Lemmatizer*\n",
    " - *CountVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,2)`\n",
    " - *GridSearch*\n",
    "  - `cv__max_features=None`\n",
    "  - `gb__loss='deviance'`\n",
    "  - `gb__max_depth=7`\n",
    "  - `gb__n_estimators=100`\n",
    "  \n",
    "**Model 4:** TF-IDF Logistic Regression\n",
    " - *Lemmatizer*\n",
    " - *TfidfVectorizer*\n",
    "  - `stop_words='english'`\n",
    "  - `ngram_range=(1,2)`\n",
    " - *GridSearch*\n",
    "  - `tf__max_features=30000`\n",
    "  - `lr__penalty='l1'`\n",
    "  - `lr__C=1`\n",
    "  - `lr__tol=.001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.read_csv('./csv/181220_new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./csv/181220_X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('./csv/181220_X_test.csv', index_col=0)\n",
    "y_train = pd.read_csv('./csv/181220_y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('./csv/181220_y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 Evaluation: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_steps = [('m1_cv',CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=35000)),\n",
    "           ('m1_mnb',MultinomialNB(alpha=1.2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1 = Pipeline(m1_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('m1_cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=35000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('m1_mnb', MultinomialNB(alpha=1.2, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9873861247372109"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340336134453782"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy against unseen posts: 84.25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84251968503937"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.score(new_test.post_lm, new_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 67\n",
      "False Positives: 12\n",
      "False Negatives: 8\n",
      "True Positives: 40\n",
      "\n",
      "Accuracy:  0.84251968503937\n",
      "Sensitivity:  0.8333333333333334\n",
      "Specificity:  0.8481012658227848\n",
      "Precision:  0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(new_test.is_ls, pipe_1.predict(new_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 Evaluation: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_steps = [('m2_cv',CountVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "           ('m2_rf',RandomForestClassifier(criterion='gini', n_estimators=99, max_depth=9))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_2 = Pipeline(m2_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('m2_cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "       ...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877365101611773"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.773109243697479"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy against unseen posts: 76.38%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7637795275590551"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.score(new_test.post_lm, new_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 53\n",
      "False Positives: 26\n",
      "False Negatives: 4\n",
      "True Positives: 44\n",
      "\n",
      "Accuracy:  0.7637795275590551\n",
      "Sensitivity:  0.9166666666666666\n",
      "Specificity:  0.6708860759493671\n",
      "Precision:  0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(new_test.is_ls, pipe_2.predict(new_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Evaluation: Gradient-Boost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_steps = [('m3_cv',CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=None)),\n",
    "           ('m3_gb',GradientBoostingClassifier(loss='deviance', n_estimators=100, max_depth=7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_3 = Pipeline(m3_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('m3_cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "       ...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985984583041345"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046218487394958"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy against unseen posts: 81.89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8188976377952756"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.score(new_test.post_lm, new_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 63\n",
      "False Positives: 16\n",
      "False Negatives: 7\n",
      "True Positives: 41\n",
      "\n",
      "Accuracy:  0.8188976377952756\n",
      "Sensitivity:  0.8541666666666666\n",
      "Specificity:  0.7974683544303798\n",
      "Precision:  0.7192982456140351\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(new_test.is_ls, pipe_3.predict(new_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 Evaluation: TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_steps = [('m4_tf',TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=30000)),\n",
    "            ('m4_ss',StandardScaler(with_mean=False)),\n",
    "            ('m4_lr',LogisticRegression(penalty='l1', C=1, tol=.001))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_4 = Pipeline(m4_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('m4_tf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True... penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99929922915206726"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80672268907563027"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy against unseen posts: 85.04%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503937007874016"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.score(new_test.post_lm, new_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 67\n",
      "False Positives: 12\n",
      "False Negatives: 7\n",
      "True Positives: 41\n",
      "\n",
      "Accuracy:  0.8503937007874016\n",
      "Sensitivity:  0.8541666666666666\n",
      "Specificity:  0.8481012658227848\n",
      "Precision:  0.7735849056603774\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(new_test.is_ls, pipe_4.predict(new_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_all = VotingClassifier([\n",
    "    ('mnb', pipe_1),\n",
    "    ('rf', pipe_2),\n",
    "    ('gb', pipe_3),\n",
    "    ('lr', pipe_4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('mnb', Pipeline(memory=None,\n",
       "     steps=[('m1_cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=35000, min_df=1,\n",
       "        ngram_range=(1, 2), ...nalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.001, verbose=0, warm_start=False))]))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_all.fit(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985984583041345"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_all.score(X_train.post_lm, y_train.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8298319327731093"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_all.score(X_test.post_lm, y_test.is_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy against unseen posts: 88.98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889763779527559"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_all.score(new_test.post_lm, new_test.is_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 70\n",
      "False Positives: 9\n",
      "False Negatives: 5\n",
      "True Positives: 43\n",
      "\n",
      "Accuracy:  0.889763779527559\n",
      "Sensitivity:  0.8958333333333334\n",
      "Specificity:  0.8860759493670886\n",
      "Precision:  0.8269230769230769\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(new_test.is_ls, vote_all.predict(new_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Multinomial Naive Bayes Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1427x35000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 90419 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = pipe_1.named_steps['m1_mnb']\n",
    "\n",
    "cv1 = pipe_1.named_steps['m1_cv']\n",
    "cv1.fit_transform(X_train.post_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_df = pd.DataFrame(m1.coef_.T, index=cv1.get_feature_names(), columns=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sound                -5.571445\n",
       "wa                   -5.814237\n",
       "just                 -5.873034\n",
       "like                 -5.911619\n",
       "ve                   -5.935506\n",
       "live                 -6.212235\n",
       "know                 -6.250139\n",
       "work                 -6.295294\n",
       "ha                   -6.301084\n",
       "need                 -6.312766\n",
       "band                 -6.330550\n",
       "speaker              -6.330550\n",
       "looking              -6.348655\n",
       "use                  -6.367095\n",
       "audio                -6.373318\n",
       "mixer                -6.392222\n",
       "time                 -6.437773\n",
       "want                 -6.457948\n",
       "mic                  -6.464765\n",
       "channel              -6.492506\n",
       "guy                  -6.521039\n",
       "thanks               -6.573018\n",
       "using                -6.573018\n",
       "way                  -6.573018\n",
       "question             -6.580669\n",
       "amp                  -6.588379\n",
       "don                  -6.635932\n",
       "monitor              -6.635932\n",
       "help                 -6.660584\n",
       "good                 -6.660584\n",
       "                       ...    \n",
       "sampling theory     -11.267419\n",
       "sand                -11.267419\n",
       "sand sound          -11.267419\n",
       "sane                -11.267419\n",
       "sane choice         -11.267419\n",
       "sang                -11.267419\n",
       "sang live           -11.267419\n",
       "sang softly         -11.267419\n",
       "samplerate          -11.267419\n",
       "sampler asio4all    -11.267419\n",
       "sampled quantized   -11.267419\n",
       "sampled create      -11.267419\n",
       "sample library      -11.267419\n",
       "sample logic        -11.267419\n",
       "sample original     -11.267419\n",
       "sample pack         -11.267419\n",
       "sample quiet        -11.267419\n",
       "sample rate         -11.267419\n",
       "sample recording    -11.267419\n",
       "sample sample       -11.267419\n",
       "sample sequence     -11.267419\n",
       "sample size         -11.267419\n",
       "sample start        -11.267419\n",
       "sample time         -11.267419\n",
       "sample trying       -11.267419\n",
       "sample ve           -11.267419\n",
       "sample want         -11.267419\n",
       "sample yes          -11.267419\n",
       "sampled             -11.267419\n",
       "rid vox             -11.267419\n",
       "Name: coef, Length: 35000, dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_df.coef.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function researched and borrowed from Stackoverflow\n",
    "# https://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers\n",
    "\n",
    "def important_features(vectorizer,classifier,n=20):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    print(\"Important words for r/audioengineering\\n\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\\n\")\n",
    "    print(\"Important words for r/livesound\\n\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words for r/audioengineering\n",
      "\n",
      "0 466.0 sound\n",
      "0 308.0 just\n",
      "0 305.0 audio\n",
      "0 289.0 like\n",
      "0 275.0 recording\n",
      "0 262.0 wa\n",
      "0 246.0 ve\n",
      "0 232.0 know\n",
      "0 229.0 track\n",
      "0 222.0 new\n",
      "0 203.0 use\n",
      "0 186.0 way\n",
      "0 178.0 sort\n",
      "0 174.0 mix\n",
      "0 171.0 thread\n",
      "-----------------------------------------\n",
      "\n",
      "Important words for r/livesound\n",
      "\n",
      "1 356.0 sound\n",
      "1 279.0 wa\n",
      "1 263.0 just\n",
      "1 253.0 like\n",
      "1 247.0 ve\n",
      "1 187.0 live\n",
      "1 180.0 know\n",
      "1 172.0 work\n",
      "1 171.0 ha\n",
      "1 169.0 need\n",
      "1 166.0 speaker\n",
      "1 166.0 band\n",
      "1 163.0 looking\n",
      "1 160.0 use\n",
      "1 159.0 audio\n"
     ]
    }
   ],
   "source": [
    "important_features(pipe_1.named_steps['m1_cv'], pipe_1.named_steps['m1_mnb'], 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest Feature Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1427x8413 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 53056 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = pipe_2.named_steps['m2_rf']\n",
    "\n",
    "cv2 = pipe_2.named_steps['m2_cv']\n",
    "cv2.fit_transform(X_train.post_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_df = pd.DataFrame(m2.feature_importances_, index=cv2.get_feature_names(), columns=['fi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6966"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_df[m2_df.fi==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_df.drop(m2_df[m2_df.fi==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "venue           2.992175e-02\n",
       "recording       1.892804e-02\n",
       "gig             1.657400e-02\n",
       "stage           1.538751e-02\n",
       "album           1.395730e-02\n",
       "drum            1.215183e-02\n",
       "mixer           1.196458e-02\n",
       "engineering     1.152045e-02\n",
       "author          1.151017e-02\n",
       "sticky          1.101322e-02\n",
       "track           1.069544e-02\n",
       "compression     9.653836e-03\n",
       "interface       9.174475e-03\n",
       "new             8.895328e-03\n",
       "event           8.349787e-03\n",
       "audio           8.276294e-03\n",
       "reddit          7.959382e-03\n",
       "foh             7.930446e-03\n",
       "title           7.501955e-03\n",
       "live            7.457397e-03\n",
       "thread          7.152979e-03\n",
       "record          6.857877e-03\n",
       "wireless        6.822146e-03\n",
       "trick           6.565180e-03\n",
       "project         6.548113e-03\n",
       "restrict_sr     6.267189e-03\n",
       "pa              5.988630e-03\n",
       "console         5.843818e-03\n",
       "friday          5.701423e-03\n",
       "master          5.621560e-03\n",
       "                    ...     \n",
       "charging        1.168733e-06\n",
       "disability      1.164820e-06\n",
       "panning         1.161813e-06\n",
       "picking         1.091824e-06\n",
       "dm64            9.623700e-07\n",
       "multipath       9.559895e-07\n",
       "q2              9.060627e-07\n",
       "staging         8.914984e-07\n",
       "kickdrum        8.911214e-07\n",
       "narrator        8.878099e-07\n",
       "chain           8.703172e-07\n",
       "marketing       8.521274e-07\n",
       "whatnot         8.439906e-07\n",
       "bassy           8.221529e-07\n",
       "ohm             8.047267e-07\n",
       "called          7.982447e-07\n",
       "lose            7.894175e-07\n",
       "pod             7.590249e-07\n",
       "caught          7.353134e-07\n",
       "donut           6.129323e-07\n",
       "replicate       5.848872e-07\n",
       "particularly    5.747174e-07\n",
       "sounding        5.742789e-07\n",
       "m7cl            5.650002e-07\n",
       "lengthened      5.591254e-07\n",
       "interested      5.307238e-07\n",
       "rough           4.106535e-07\n",
       "hanging         3.824221e-07\n",
       "fast            2.782607e-07\n",
       "depict          2.269543e-07\n",
       "Name: fi, Length: 1447, dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_df.fi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GradientBoost Decision Tree Feature Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1427x62698 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 118117 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = pipe_3.named_steps['m3_gb']\n",
    "\n",
    "cv3 = pipe_3.named_steps['m3_cv']\n",
    "cv3.fit_transform(X_train.post_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_df = pd.DataFrame(m3.feature_importances_, index=cv3.get_feature_names(), columns=['fi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61088"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_df[m3_df.fi==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_df.drop(m3_df[m3_df.fi==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recording              5.773130e-02\n",
       "venue                  4.778125e-02\n",
       "track                  4.730125e-02\n",
       "mixer                  3.424911e-02\n",
       "gig                    3.087447e-02\n",
       "audio                  2.798132e-02\n",
       "live                   2.607853e-02\n",
       "studio                 2.311059e-02\n",
       "pa                     1.931976e-02\n",
       "album                  1.699700e-02\n",
       "wireless               1.686895e-02\n",
       "tuesday                1.575035e-02\n",
       "mix                    1.424106e-02\n",
       "daily                  1.322172e-02\n",
       "interface              1.273513e-02\n",
       "backing track          1.236456e-02\n",
       "console                1.189749e-02\n",
       "stage                  1.044619e-02\n",
       "sound                  1.021441e-02\n",
       "foh                    1.011606e-02\n",
       "response               9.096207e-03\n",
       "engineering            8.829859e-03\n",
       "receiver               8.753419e-03\n",
       "x32                    8.437276e-03\n",
       "make                   8.282002e-03\n",
       "record                 7.987869e-03\n",
       "drum                   7.836628e-03\n",
       "thread                 7.666080e-03\n",
       "thing                  7.544872e-03\n",
       "sample                 7.369759e-03\n",
       "                           ...     \n",
       "cheap tablet           8.655461e-09\n",
       "preface                7.991982e-09\n",
       "dap cm                 6.797814e-09\n",
       "mac                    6.598463e-09\n",
       "playing live           6.419320e-09\n",
       "compressor master      6.409091e-09\n",
       "approach recording     6.393843e-09\n",
       "effect cardioid        6.268285e-09\n",
       "begun                  5.912261e-09\n",
       "sharp                  5.700301e-09\n",
       "recording appears      5.618185e-09\n",
       "turn audio             5.459700e-09\n",
       "ve wondered            4.669455e-09\n",
       "roland look            4.654011e-09\n",
       "clear patch            4.521410e-09\n",
       "audible important      3.914349e-09\n",
       "regret                 3.599879e-09\n",
       "fit                    3.357569e-09\n",
       "hold horse             3.187673e-09\n",
       "resonance              3.178812e-09\n",
       "pretty warm            2.993736e-09\n",
       "aes50                  2.544275e-09\n",
       "quick                  1.961768e-09\n",
       "using input            1.850240e-09\n",
       "main purpose           1.428678e-09\n",
       "silly lose             1.424892e-09\n",
       "wanted                 8.644539e-10\n",
       "reference recording    5.891073e-10\n",
       "practise               2.663398e-10\n",
       "uncharted territory    2.012078e-10\n",
       "Name: fi, Length: 1610, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_df.fi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1427x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 85419 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = pipe_4.named_steps['m4_lr']\n",
    "\n",
    "tf4 = pipe_4.named_steps['m4_tf']\n",
    "tf4.fit_transform(X_train.post_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_df = pd.DataFrame(m4.coef_.T, index=tf4.get_feature_names(), columns=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studio         -0.423051\n",
       "interface      -0.392248\n",
       "recording      -0.352222\n",
       "track          -0.345991\n",
       "drum           -0.284348\n",
       "focusrite      -0.278234\n",
       "album          -0.273362\n",
       "noise          -0.269377\n",
       "record         -0.264122\n",
       "mastering      -0.262601\n",
       "bass           -0.237672\n",
       "recorded       -0.221967\n",
       "engineering    -0.215780\n",
       "session        -0.210754\n",
       "thing          -0.207626\n",
       "topic          -0.205324\n",
       "audio          -0.200939\n",
       "way            -0.198831\n",
       "project        -0.195182\n",
       "reverb         -0.194448\n",
       "mix            -0.191028\n",
       "sm7b           -0.187119\n",
       "car            -0.185066\n",
       "sample         -0.183184\n",
       "production     -0.178777\n",
       "tracking       -0.176243\n",
       "plugin         -0.172085\n",
       "improve        -0.170546\n",
       "song           -0.157336\n",
       "guitar pedal   -0.147453\n",
       "                  ...   \n",
       "case            0.175549\n",
       "vocalist        0.175683\n",
       "shure           0.177090\n",
       "sound guy       0.188930\n",
       "got             0.190835\n",
       "receiver        0.191993\n",
       "ipad            0.192117\n",
       "main            0.192637\n",
       "rig             0.193438\n",
       "powered         0.195398\n",
       "rack            0.196899\n",
       "today           0.198191\n",
       "option          0.211932\n",
       "church          0.225400\n",
       "event           0.251244\n",
       "live sound      0.252999\n",
       "x32             0.253230\n",
       "week            0.265088\n",
       "board           0.271626\n",
       "wireless        0.308316\n",
       "midas           0.320143\n",
       "tonight         0.324834\n",
       "console         0.368780\n",
       "mixer           0.392732\n",
       "foh             0.411319\n",
       "live            0.432581\n",
       "pa              0.461868\n",
       "stage           0.471363\n",
       "gig             0.570933\n",
       "venue           0.625922\n",
       "Name: coef, Length: 30000, dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_df.coef.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit API Classification & Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom Ludlow, DSI-NY-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLP to identify posts from **r/audioengineering** and **r/livesound**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# preprocessing imports\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state var\n",
    "r = 1220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./csv/181220_X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('./csv/181220_X_test.csv', index_col=0)\n",
    "y_train = pd.read_csv('./csv/181220_y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('./csv/181220_y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train, columns=['is_ls'])\n",
    "y_test = pd.DataFrame(y_test, columns=['is_ls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1427, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1427, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GridSearchCV` tool allows us to program multiple hyperparameters across our models.  It will generate a model with each combination of our desired hyperparameters, and optimize the highest-scoring result.\n",
    "\n",
    "We will run a single model for each of the following 6 classifiers:\n",
    " - Multinomial Naive Bayes\n",
    " - K-Nearest Neighbors\n",
    " - Logistic Regression\n",
    " - Random Forest\n",
    " - AdaBoost (adaptive boost)\n",
    " - Gradient Boost\n",
    " \n",
    "We will run two GridSearches to benchmark these models for two feature extraction techniques: `CountVectorizer` and `TfidfVectorizer`.  We can use the accuracy of the results to narrow our model selection to the most effective approaches.\n",
    "\n",
    "As these models execute, the results will be displayed, then stored into a DataFrame for final comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list_gr_cv = [ # list of pipeline steps for each model combo\n",
    "    [('cv',CountVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('cv',CountVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('cv',CountVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())],\n",
    "    [('cv',CountVectorizer()),('rf',RandomForestClassifier())],\n",
    "    [('cv',CountVectorizer()),('ada',AdaBoostClassifier())],\n",
    "    [('cv',CountVectorizer()),('gb',GradientBoostingClassifier())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','knn','logreg','rf','ada','gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_cv = [\n",
    "    {\"cv__stop_words\":['english'], \"cv__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"cv__stop_words\":['english'], \"cv__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"cv__stop_words\":['english'], \"cv__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"cv__stop_words\":['english'], \"cv__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"cv__stop_words\":['english'], \"cv__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"cv__stop_words\":['english'], \"cv__ngram_range\":[(1,1),(1,2)]}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame\n",
    "\n",
    "grid_results = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','tn','fp','fn','tp'])\n",
    "grid_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_post = X_train['post_lm']\n",
    "X_test_pre_post = X_test['post_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}\n",
      "0.995795374912 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836134453782 \n",
      "\n",
      "True Negatives: 195\n",
      "False Positives: 36\n",
      "False Negatives: 42\n",
      "True Positives: 203 \n",
      "\n",
      "Model:  knn\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.547302032235 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [00:03<00:07,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533613445378 \n",
      "\n",
      "True Negatives: 10\n",
      "False Positives: 221\n",
      "False Negatives: 1\n",
      "True Positives: 244 \n",
      "\n",
      "Model:  logreg\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.999299229152 \n",
      "\n",
      "0.766806722689 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [00:05<00:05,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 174\n",
      "False Positives: 57\n",
      "False Negatives: 54\n",
      "True Positives: 191 \n",
      "\n",
      "Model:  rf\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.985984583041 \n",
      "\n",
      "0.773109243697 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 187\n",
      "False Positives: 44\n",
      "False Negatives: 64\n",
      "True Positives: 181 \n",
      "\n",
      "Model:  ada\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.861948142957 \n",
      "\n",
      "0.77731092437 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [00:10<00:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 178\n",
      "False Positives: 53\n",
      "False Negatives: 53\n",
      "True Positives: 192 \n",
      "\n",
      "Model:  gb\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}\n",
      "0.913805185704 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 6/6 [00:21<00:00,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813025210084 \n",
      "\n",
      "True Negatives: 168\n",
      "False Positives: 63\n",
      "False Negatives: 26\n",
      "True Positives: 219 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(steps_list_gr_cv))):           # timed loop through index of number of steps\n",
    "    pipe = Pipeline(steps=steps_list_gr_cv[i])         # configure pipeline for each model\n",
    "    grid = GridSearchCV(pipe, pipe_params_cv[i], cv=3) # fit GridSearchCV to model and model's params\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    grid.fit(X_train_pre_post, y_train)\n",
    "    \n",
    "    print('Model: ',steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', grid.best_params_)\n",
    "    model_results['best_params'] = grid.best_params_\n",
    "\n",
    "    print(grid.score(X_train_pre_post, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = grid.score(X_train_pre_post, y_train)\n",
    "    \n",
    "    print(grid.score(X_test_pre_post, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = grid.score(X_test_pre_post, y_test)\n",
    "\n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_pre_post)).ravel() \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    model_results['tn'] = tn\n",
    "\n",
    "    print(\"False Positives: %s\" % fp)  \n",
    "    model_results['fp'] = fp\n",
    "\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    model_results['fn'] = fn\n",
    "\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    model_results['tp'] = tp\n",
    "\n",
    "    grid_results = grid_results.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_cv = grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'cv__ngram_range': (1, 2), 'cv__stop_words': ...</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>195.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gb</td>\n",
       "      <td>{'cv__ngram_range': (1, 2), 'cv__stop_words': ...</td>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>168.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.861948</td>\n",
       "      <td>0.777311</td>\n",
       "      <td>178.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.985985</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>187.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.766807</td>\n",
       "      <td>174.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.547302</td>\n",
       "      <td>0.533613</td>\n",
       "      <td>10.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "0  multi_nb  {'cv__ngram_range': (1, 2), 'cv__stop_words': ...   \n",
       "5        gb  {'cv__ngram_range': (1, 2), 'cv__stop_words': ...   \n",
       "4       ada  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "3        rf  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "2    logreg  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "1       knn  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "\n",
       "   train_accuracy  test_accuracy     tn     fp    fn     tp  \n",
       "0        0.995795       0.836134  195.0   36.0  42.0  203.0  \n",
       "5        0.913805       0.813025  168.0   63.0  26.0  219.0  \n",
       "4        0.861948       0.777311  178.0   53.0  53.0  192.0  \n",
       "3        0.985985       0.773109  187.0   44.0  64.0  181.0  \n",
       "2        0.999299       0.766807  174.0   57.0  54.0  191.0  \n",
       "1        0.547302       0.533613   10.0  221.0   1.0  244.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list_gr_tf = [ # list of pipeline steps for each model combo\n",
    "    [('tf',TfidfVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())],\n",
    "    [('tf',TfidfVectorizer()),('rf',RandomForestClassifier())],\n",
    "    [('tf',TfidfVectorizer()),('ada',AdaBoostClassifier())],\n",
    "    [('tf',TfidfVectorizer()),('gb',GradientBoostingClassifier())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','knn','logreg','rf','ada','gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_tf = [\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]},\n",
    "    {\"tf__stop_words\":['english'], \"tf__ngram_range\":[(1,1),(1,2)]}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame\n",
    "\n",
    "grid_results = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','tn','fp','fn','tp'])\n",
    "grid_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_post = X_train['post_lm']\n",
    "X_test_pre_post = X_test['post_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:01<00:06,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.957252978276 \n",
      "\n",
      "0.819327731092 \n",
      "\n",
      "True Negatives: 195\n",
      "False Positives: 36\n",
      "False Negatives: 50\n",
      "True Positives: 195 \n",
      "\n",
      "Model:  knn\n",
      "Best Params:  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "0.540995094604 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [00:03<00:06,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.529411764706 \n",
      "\n",
      "True Negatives: 7\n",
      "False Positives: 224\n",
      "False Negatives: 0\n",
      "True Positives: 245 \n",
      "\n",
      "Model:  logreg\n",
      "Best Params:  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "0.999299229152 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [00:05<00:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821428571429 \n",
      "\n",
      "True Negatives: 183\n",
      "False Positives: 48\n",
      "False Negatives: 37\n",
      "True Positives: 208 \n",
      "\n",
      "Model:  rf\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.995795374912 \n",
      "\n",
      "0.756302521008 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [00:07<00:03,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 184\n",
      "False Positives: 47\n",
      "False Negatives: 69\n",
      "True Positives: 176 \n",
      "\n",
      "Model:  ada\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.868955851437 \n",
      "\n",
      "0.760504201681 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [00:10<00:02,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 176\n",
      "False Positives: 55\n",
      "False Negatives: 59\n",
      "True Positives: 186 \n",
      "\n",
      "Model:  gb\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.924316748423 \n",
      "\n",
      "0.800420168067 \n",
      "\n",
      "True Negatives: 174\n",
      "False Positives: 57\n",
      "False Negatives: 38\n",
      "True Positives: 207 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:20<00:00,  4.69s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(steps_list_gr_tf))):           # timed loop through index of number of steps\n",
    "    pipe = Pipeline(steps=steps_list_gr_tf[i])         # configure pipeline for each model\n",
    "    grid = GridSearchCV(pipe, pipe_params_tf[i], cv=3) # fit GridSearchCV to model and model's params\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    grid.fit(X_train_pre_post, y_train)\n",
    "    \n",
    "    print('Model: ',steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', grid.best_params_)\n",
    "    model_results['best_params'] = grid.best_params_\n",
    "\n",
    "    print(grid.score(X_train_pre_post, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = grid.score(X_train_pre_post, y_train)\n",
    "    \n",
    "    print(grid.score(X_test_pre_post, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = grid.score(X_test_pre_post, y_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_pre_post)).ravel()\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    model_results['tn'] = tn\n",
    "\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    model_results['fp'] = fp\n",
    "\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    model_results['fn'] = fn\n",
    "\n",
    "    print(\"True Positives: %s\" % tp, '\\n')\n",
    "    model_results['tp'] = tp\n",
    "\n",
    "    grid_results = grid_results.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_tf = grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding columns for the gap between train and set accuracy scores.  This will tell us about the level of overfitting that may be present in each model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_tf['tt_gap'] = grid_results_tf['train_accuracy'] - grid_results_tf['test_accuracy']\n",
    "grid_results_cv['tt_gap'] = grid_results_cv['train_accuracy'] - grid_results_cv['test_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **baseline accuracy** is the likelihood of a post being `is_is=1` based solely on the percentage of our dataset that is our target value.  Here, we normalize our value counts to show a baseline accuracy of **51.4%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.514366\n",
       "0    0.485634\n",
       "Name: is_ls, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "y_train.is_ls.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_tf['ba_gap'] = grid_results_tf['test_accuracy'] - y_train.is_ls.value_counts(normalize=True)[1]\n",
    "grid_results_cv['ba_gap'] = grid_results_cv['test_accuracy'] - y_train.is_ls.value_counts(normalize=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By consolidating and sorting our results values by `test_accuracy`, we can assess which models will be the best starting points.  Overall, CountVectorized and TF-IDF models performed similarly.  Because CountVectorized registered the highest score, we will use that as our vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>tt_gap</th>\n",
       "      <th>ba_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'cv__ngram_range': (1, 2), 'cv__stop_words': ...</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>195.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.159661</td>\n",
       "      <td>0.321769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gb</td>\n",
       "      <td>{'cv__ngram_range': (1, 2), 'cv__stop_words': ...</td>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>168.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.100780</td>\n",
       "      <td>0.298659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.861948</td>\n",
       "      <td>0.777311</td>\n",
       "      <td>178.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.084637</td>\n",
       "      <td>0.262945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.985985</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>187.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.212875</td>\n",
       "      <td>0.258743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.766807</td>\n",
       "      <td>174.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.232493</td>\n",
       "      <td>0.252441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.547302</td>\n",
       "      <td>0.533613</td>\n",
       "      <td>10.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.019248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "0  multi_nb  {'cv__ngram_range': (1, 2), 'cv__stop_words': ...   \n",
       "5        gb  {'cv__ngram_range': (1, 2), 'cv__stop_words': ...   \n",
       "4       ada  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "3        rf  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "2    logreg  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "1       knn  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "\n",
       "   train_accuracy  test_accuracy     tn     fp    fn     tp    tt_gap  \\\n",
       "0        0.995795       0.836134  195.0   36.0  42.0  203.0  0.159661   \n",
       "5        0.913805       0.813025  168.0   63.0  26.0  219.0  0.100780   \n",
       "4        0.861948       0.777311  178.0   53.0  53.0  192.0  0.084637   \n",
       "3        0.985985       0.773109  187.0   44.0  64.0  181.0  0.212875   \n",
       "2        0.999299       0.766807  174.0   57.0  54.0  191.0  0.232493   \n",
       "1        0.547302       0.533613   10.0  221.0   1.0  244.0  0.013689   \n",
       "\n",
       "     ba_gap  \n",
       "0  0.321769  \n",
       "5  0.298659  \n",
       "4  0.262945  \n",
       "3  0.258743  \n",
       "2  0.252441  \n",
       "1  0.019248  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_cv.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>tt_gap</th>\n",
       "      <th>ba_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': ...</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>183.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.177871</td>\n",
       "      <td>0.307063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>0.957253</td>\n",
       "      <td>0.819328</td>\n",
       "      <td>195.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>0.304962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gb</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>0.924317</td>\n",
       "      <td>0.800420</td>\n",
       "      <td>174.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.123897</td>\n",
       "      <td>0.286054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>0.868956</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>176.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.108452</td>\n",
       "      <td>0.246138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>184.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.239493</td>\n",
       "      <td>0.241937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': ...</td>\n",
       "      <td>0.540995</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>7.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.015046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "2    logreg  {'tf__ngram_range': (1, 2), 'tf__stop_words': ...   \n",
       "0  multi_nb  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "5        gb  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "4       ada  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "3        rf  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "1       knn  {'tf__ngram_range': (1, 2), 'tf__stop_words': ...   \n",
       "\n",
       "   train_accuracy  test_accuracy     tn     fp    fn     tp    tt_gap  \\\n",
       "2        0.999299       0.821429  183.0   48.0  37.0  208.0  0.177871   \n",
       "0        0.957253       0.819328  195.0   36.0  50.0  195.0  0.137925   \n",
       "5        0.924317       0.800420  174.0   57.0  38.0  207.0  0.123897   \n",
       "4        0.868956       0.760504  176.0   55.0  59.0  186.0  0.108452   \n",
       "3        0.995795       0.756303  184.0   47.0  69.0  176.0  0.239493   \n",
       "1        0.540995       0.529412    7.0  224.0   0.0  245.0  0.011583   \n",
       "\n",
       "     ba_gap  \n",
       "2  0.307063  \n",
       "0  0.304962  \n",
       "5  0.286054  \n",
       "4  0.246138  \n",
       "3  0.241937  \n",
       "1  0.015046  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_tf.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at model types, we can see that the CountVectorized Multinomial Naive-Bayes and TF-IDF Logistic Regression performed best on an initial run.  We will select these two, as well as the RandomForest model, which was requested by the project requirements, and GradientBoost Decision Tree to enhance modeling accuracy.  We will continue to optimize each of these models.\n",
    "\n",
    "### Model Selections: \n",
    "#### 1. Lemmatized CountVectorizer Multinomial Naive-Bayes\n",
    "  - `cv__ngram_range=(1,2)`\n",
    "  - `cv__stop_words='english'`\n",
    "  \n",
    "#### 2. Lemmatized CountVectorizer Random Forest \n",
    "*(project requirement)*\n",
    "  - `cv__ngram_range=(1,1)`\n",
    "  - `cv__stop_words='english'`\n",
    "  \n",
    "#### 3. Lemmatized CountVectorizer Gradient-Boost Decision Tree\n",
    "  - `cv__ngram_range=(1,2)`\n",
    "  - `cv__stop_words='english'`\n",
    "  \n",
    "#### 4. Lemmatized TF-IDF Scaled Logistic Regression\n",
    "  - `tf__ngram_range=(1,2)`\n",
    "  - `tf__stop_words='english'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to Notebook 4: Model Optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
